# Snowflake-Snowpro
##### 1_hands_on - This is a SQL script that uses role-based access control (RBAC) and privilege management in Snowflake. It creates a new database, schema, and table, defines a custom role with various privileges, and assigns a new user to the role. It also shows how to grant and revoke privileges and automate privilege management with future grants. The script can be used as a template for RBAC in Snowflake.
##### 2_hands_on - This code demonstrates how to manage masking policies and row access policies in Snowflake, a cloud-based data warehousing platform. It also shows how to implement centralized policy management. The script creates a database, schema, and table for test data, defines roles with various privileges, and creates and applies masking and row access policies on the table. Finally, the script creates a mapping table and uses it to implement a more complex row access policy.
##### 3_hands_on - This code demonstrates how to create and manage virtual warehouses in Snowflake, a cloud-based data warehousing platform. The script creates a new virtual warehouse with a specified size, auto-suspend time, and auto-resume state. It then shows how to manually suspend and resume the virtual warehouse and how to set configurations on-the-fly. Finally, the script drops the virtual warehouse.
##### 4_hands_on - This code demonstrates how to monitor virtual warehouse usage and credit consumption in Snowflake. It includes SQL queries to view the total credits used by a specific virtual warehouse, as well as warehouse metering history using the INFORMATION_SCHEMA. It also includes an example of creating a resource monitor and applying it to a virtual warehouse.
##### 5_hands_on - This script demonstrates the creation and configuration of a multi-cluster warehouse in Snowflake. It sets the MIN_CLUSTER_COUNT and MAX_CLUSTER_COUNT options, which determine the minimum and maximum number of clusters that the warehouse can scale to, respectively. It also sets the SCALING_POLICY option to 'STANDARD', which enables Snowflake to automatically scale the warehouse up and down based on the workload. The script then creates three users with the SYSADMIN role and sets their default warehouse to the multi-cluster warehouse. Finally, the users are dropped, and the warehouse is deleted.
##### 6_hands_on - This code shows various ways to insert data into a table in Snowflake. It creates a database and a schema, then creates a table named FILMS with columns ID, TITLE, and RELEASE_DATE. The code demonstrates inserting rows into the FILMS table using SELECT, VALUES, and INSERT INTO statements, and copying data from one table to another. It also shows how to overwrite an existing table with new data. Finally, it drops the database created earlier to clear down resources.
##### 7_hands_on - This code demonstrates how to work with stages in Snowflake. It covers creating internal and external stages, listing staged data files, using the PUT command to upload files to stages, querying staged data files, and removing files from stages. It also includes creating a file format to parse files in a stage and querying metadata columns.
##### 8_hands_on - This script covers various aspects of loading data into Snowflake through the COPY INTO statement, including file formats, file format options, copy options, load transformations, and load validations. It also includes examples of using internal and external stages, as well as querying staged data files.
##### 9_hands_on - This script creates a file format for JSON files, uploads a JSON file to a staging area, and loads it into a table using the ELT method. The semi-structured data is queried using different approaches, including using functions to extract values from the JSON objects. The ETL method of loading semi-structured data into a table with a predefined schema is also explored, using the COPY INTO statement. Finally, JSON object properties are matched with table columns using column names.
##### 10_hands_on - This script covers four different aspects related to query history in Snowflake: using the Query History page, Query Profile, Account usage view, and Information Schema table function. We demonstrate how to view query history and extract relevant information such as the longest running queries. Finally, we create a temporary database for access to the Information Schema and query the query_history() table function.
##### 11_hands_on - In this script, three types of caching in Snowflake are explored: metadata cache, results cache, and local storage in virtual warehouses. Various queries and functions are used to demonstrate how these caching mechanisms work and their effects on query performance. Additionally, context functions, object descriptions, and system functions are briefly mentioned. Finally, cached results are turned off to illustrate the difference in performance when cached results are disabled.
##### 12_hands_on - This script explores two different aspects related to clustering in Snowflake. Firstly, it uses the SYSTEM$CLUSTERING_INFORMATION function to check for the presence of cluster keys on tables and examine their effects on query performance. Secondly, it demonstrates how to monitor the costs and usage of the Automatic Clustering serverless feature. It also briefly mentions how to apply a clustering key to a table.
##### 13_hands_on - In this script, databases and schemas are introduced and the different types of tables and views that can be created within them are explored in Snowflake. A demo database and schema are created to illustrate the creation and querying of permanent, temporary, and transient tables. External tables are briefly mentioned, and their metadata refresh is demonstrated. Additionally, three views of different types (standard, secure, and materialized) are created, and the get_ddl function is used to retrieve the DDL of views.
##### 14_hands_on - This script demonstrates the usage of three types of user-defined functions (UDFs) in Snowflake: SQL UDFs, JavaScript UDFs, and overloaded JavaScript UDFs. It also shows how to create an external function using an API integration object and a proxy service URL. Furthermore, we create a stored procedure using JavaScript and execute it to truncate all tables in a given schema. However, it should be noted that stored procedures cannot be used as part of a SQL statement. Finally, we create a demo database and schema and insert some data into it to test the procedure.
##### 15_hands_on - This script covers three different topics related to SnowSQL. First, it demonstrates how to configure SnowSQL with the proper account, region, and cloud provider information using the command line interface. Second, it demonstrates how to query with SnowSQL using either the -q option or by creating and executing a file containing the SQL statement. Finally, it covers the use of variables in SnowSQL and provides examples of how to define and use them in queries.
##### 16_hands_on - This script covers how to share data across Snowflake accounts using shares. It demonstrates creating a demo database and schema, populating it with a table and a secure view, and creating a share. Usage and select privileges are granted on the table and schema to the share. Additionally, a reader account is created and added to the share. A new database is created in the reader account using the share and imported privileges are granted on the database to the SYSADMIN role. A warehouse is also created in the reader account, and the shared table and view are queried. Additional objects are added to the share, and the view is queried from the reader account. Finally, the reader account's access to the share is removed. It is also noted that the grant will need to be reissued if changes are made to a definition of a schema-level object.
##### 17_hands_on - This script demonstrates how to import a share from the Snowflake Data Marketplace and use it to query data. Specifically, we use a share named "public.OAG_schedule" to query flight schedules between the US and Paris for the current date. We filter the results by departure country, arrival city, and flight date.
##### 18_hands_on - In this script, Snowflake's Time Travel feature is covered. The script creates a demo database and schema with a table, and verifies the DATA_RETENTION_TIME_IN_DAYS parameter using the SHOW command. The parameter is then updated for the database, schema, and table using the ALTER command, and Time Travel is disabled by setting the schema's retention time to 0. The UNDROP command is used to restore a dropped table, and the SHOW TABLES HISTORY command is used to verify it. The AT and BEFORE keywords are used to select historical data, and a restored table is created using data from before a truncate command. The script concludes by clearing down the resources.
##### 19_hands_on - In this script, Snowflake's object cloning feature is covered. A demo database and schema are created and populated with a table. Cloning is demonstrated by creating a clone of the table and then a clone of the clone. The script also shows how to clone entire databases and schemas recursively. It is also demonstrated that adding data to a cloned table in the cloned database incurs additional costs as the data starts to store micro-partitions. The script also shows how to create a clone from a past point in time using Time Travel. Finally, the resources are cleared down.
##### Intro - In this script, the focus is on setting up SnowSQL, a command-line tool that allows interaction with Snowflake. The script involves installing the downloaded version of SnowSQL and navigating to its configuration file. It also covers the process of adding necessary details, such as account locator, cloud provider region, username, and password to the configuration file using a text editor. The script further includes opening SnowSQL and querying the current version of Snowflake.

